\chapter{Package Technicalities}\label{app:techn}

The entire project runs in Python of version at least 3.6\footnote{\url{https://python.org}} and bash\footnote{\url{https://gnu.org/software/bash}}.
The following libraries are used:

\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
\textbf{library} & \textbf{purpose} \\
\midrule

nltk & tokenizer, Na\"{i}ve Bayes\\
pandas & DatFrame for storing raw data in memory\\
scipy & sparse matrix for storing features\\
yaml & parser for configuration file \\
geneea-nlp-client & parser for loading Geneea analysis\\
gensim & compute cosine similarity \todoA{unused} \\
fasttext & classification model \\
aspell & spell checking \\


\bottomrule
\end{tabular}

\caption{Used libraries}\label{tab:libs}
\end{table}

The project is executed with make\footnote{url{https://www.gnu.org/software/make}}.
By default, it runs all experiments files defined in directory \texttt{experiments}.
The entire project can be run by:

\begin{code}
make run
\end{code}

Or for demonstration running with a small subset of data:

\begin{code}
make run_sample
\end{code}

Because Geneea analysis is carried out remotely, \texttt{make} will prompt user for copying that file when appropriate.

Results are stored in \texttt{graphs/\textit{timestamp}}.
A new folder for statistics is created every run to prevent accidental overwriting of already obtained results.


\section{Experiments File}

This YAML\footnote{\url{https://yaml.org}}  file contains entire configuration of experiments conducted.
It lists classification tasks and specifies graphs to be plotted.
Each task is a definition of a classifier.
Evaluation element is a definition what properties should be plotted in a graph.

Experiments file has the following format.
The root element is a dictionary with three parts;
\texttt{config}, \texttt{tasks} and \texttt{graphs}.
An example file can be found bellow.

\begin{code}
config:
  chunks: 10
  mi: true
  l_curves: false
  max_ngrams: 100
  max_tfidf: 100
tasks:
  - name: 'zero-R'
    classificator: 'baseline'
    features:
      - REVIEWLEN
      - UNIGRAMS
    preprocessing:
      - 'mutualinformation'
      - 'featurematrixconversion'
    extra_data: []
    config:
      algorithm: 'zero-R'
      features_to_select: 2
graphs:
  - name: 'baseline'
    data:
      zero-R:
        - 'f-measure'
\end{code}

The config section is a dictionary.
It must contain the elements specified in \autoref{tab:config_yaml}.

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
\textbf{key} & \textbf{datatype} & \textbf{value} \\
\midrule

chunks & int & parameter $k$  k-fold crossvalidation\\
mi & bool & if mutual information should be calculated\\
l\_curves & bool & ordinary/learning curves evaluation\\
max\_ngrams & int & number of unigrams used \\
max\_tfidf & int & number of words for TF-IDF used\\

\bottomrule
\end{tabular}

\caption{Config section}\label{tab:config_yaml}
\end{table}


The section \texttt{experiments} is a list of classification tasks.
Each element is a dictionary specifying the exact parameters.
Descriptions of individual fields is in \autoref{tab:exp_dict}.
The list \texttt{features} consists of names as defined in FeatureSetEnum.
The exact definition can be found in \autoref{tab:fea_grp}.
\texttt{extra\_data} is any property of instances available in the raw data.
An example is the original text or business attributes.

\begin{table}[h!]

\centering
\begin{tabular}{lll}
\toprule
\textbf{element name} & \textbf{type} & \textbf{meaning}\\
\midrule
name 			& string	& identification referred to in graphs\\
classificator 	& string	& used classifier\\
features 		& list		& used features \\
preprocessing 	& list		& applied preprocessors in the order\\
extra\_data 	& list 		& extra attributes passed to the first preprocessor \\
config			& dict		& extra configuration for all parts of pipeline \\
\bottomrule
\end{tabular}

\caption{Experiment Configuration}\label{tab:exp_dict}
\end{table}


The last section \texttt{graphs} is used for specifying what graphs will be plotted.
It is a list of individual figures.
Each figure is a dictionary of two elements; \texttt{name} and \texttt{data}.
Name specifies the filenames of the resulting graph ---
for each figure png and csv files will be created.
Element \texttt{data} specifies what evaluation metrics for what classifiers will be used.
It is a dictionary of experiment names, values being a list of all metrics to be output.


\section{Defining New Preprocessors and Classifiers}

A preprocessor must be defined in directory \texttt{preprocessors} and be a child of \texttt{preprocessors/preprocessingbase.py}.
Also, its name must be added into \texttt{preprocessors/\_\_init\_\_.py}.
Analogously, a new classifier is to be created in directory \texttt{classifiers}.

The input and output formats of preprocessors is arbitrary, so long the following conditions are met.
First, adjacent units must be compatible.
Second, the first preprocessor in the pipeline must take \texttt{feature\_dict} with possibly additional data specified in \texttt{extra\_data} as returned by \texttt{load\_data.Data.get\_feature\_dict}.
Lastly, the last preprocessor must be compatible with the input of the used classifier.

The input of the classifier is up to the user.
However, the output of the classifier must be the predicted label.
